import cv2
import numpy as np
import onnxruntime

def simple_onnx_test(onnx_model_path, image_path, conf_thres=0.5, iou_thres=0.4):
    """
    å®Œæ•´ ONNX æµ‹è¯•ï¼ˆå«åå¤„ç†ï¼Œç›´æ¥è¾“å‡ºæ£€æµ‹åˆ°çš„ç›®æ ‡ï¼‰
    """
    # åŠ è½½æ¨¡å‹
    session = onnxruntime.InferenceSession(
        onnx_model_path,
        providers=['CPUExecutionProvider']
    )
    input_name = session.get_inputs()[0].name
    input_shape = session.get_inputs()[0].shape  # (1,3,640,640)
    img_h, img_w = input_shape[2], input_shape[3]

    # é¢„å¤„ç†ï¼ˆé€‚é…æ¨¡å‹è¾“å…¥ 640x640ï¼‰
    image = cv2.imread(image_path)
    original_h, original_w = image.shape[:2]
    img = cv2.resize(image, (img_w, img_h))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32) / 255.0
    img = np.transpose(img, (2, 0, 1))
    img = np.expand_dims(img, axis=0)

    # æ¨ç†
    outputs = session.run(None, {input_name: img})[0]  # å–ç¬¬ä¸€ä¸ªè¾“å‡ºå¼ é‡

    # -------------------------- æ ¸å¿ƒï¼šYOLO åå¤„ç† --------------------------
    # 1. è¿‡æ»¤ä½ç½®ä¿¡åº¦æ¡†
    boxes = []
    confidences = []
    class_ids = []
    for box in outputs[0]:  # éå†æ‰€æœ‰å€™é€‰æ¡†
        x, y, w, h, conf = box[:5]
        class_scores = box[5:]
        if conf < conf_thres:
            continue  # è·³è¿‡ä½ç½®ä¿¡åº¦æ¡†
        class_id = np.argmax(class_scores)  # å–åˆ†æ•°æœ€é«˜çš„ç±»åˆ«
        boxes.append([x, y, w, h])
        confidences.append(conf)
        class_ids.append(class_id)

    # 2. NMS å»é‡ï¼ˆå»æ‰é‡å æ¡†ï¼‰
    indices = cv2.dnn.NMSBoxes(
        boxes, confidences, conf_thres, iou_thres
    )

    # 3. è½¬æ¢åæ ‡åˆ°åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆæ¨¡å‹è¾“å…¥ 640x640 â†’ åŸå§‹å›¾åƒå°ºå¯¸ï¼‰
    final_results = []
    if len(indices) > 0:
        for i in indices.flatten():
            x, y, w, h = boxes[i]
            # YOLO è¾“å‡ºæ˜¯ä¸­å¿ƒåæ ‡ (x,y) + å®½é«˜ (w,h)ï¼Œè½¬æˆå¯¹è§’åæ ‡ (x1,y1,x2,y2)
            x1 = int((x - w/2) * (original_w / img_w))
            y1 = int((y - h/2) * (original_h / img_h))
            x2 = int((x + w/2) * (original_w / img_w))
            y2 = int((y + h/2) * (original_h / img_h))
            final_results.append({
                "class_id": class_ids[i],
                "confidence": round(confidences[i], 2),
                "box": [x1, y1, x2, y2]
            })

    # -------------------------- è¾“å‡ºæœ€ç»ˆæ£€æµ‹ç»“æœ --------------------------
    print("="*50)
    print(f"ğŸ“Š æœ€ç»ˆæ£€æµ‹ç»“æœï¼ˆç½®ä¿¡åº¦é˜ˆå€¼ï¼š{conf_thres}ï¼‰")
    print(f"âœ… å…±æ£€æµ‹åˆ° {len(final_results)} ä¸ªç›®æ ‡")
    for i, res in enumerate(final_results, 1):
        print(f"ç›®æ ‡ {i}ï¼šç±»åˆ« ID {res['class_id']}ï¼Œç½®ä¿¡åº¦ {res['confidence']}ï¼Œä½ç½® {res['box']}")
    
    # å¯è§†åŒ–æ£€æµ‹ç»“æœï¼ˆåœ¨å›¾åƒä¸Šç”»æ¡†ï¼‰
    for res in final_results:
        x1, y1, x2, y2 = res["box"]
        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
        label = f"Class{res['class_id']} {res['confidence']}"
        cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
    cv2.imwrite("onnx_detection_result.jpg", image)
    print(f"\nğŸ“ æ£€æµ‹ç»“æœå·²ä¿å­˜ä¸ºï¼šonnx_detection_result.jpg")

    return final_results

if __name__ == '__main__':
    onnx_model_path = "LR.onnx"
    image_path = "2.jpg"
    try:
        simple_onnx_test(onnx_model_path, image_path)
        print("\nâœ… å®Œæ•´æ£€æµ‹æµ‹è¯•æˆåŠŸï¼")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")