import pygame
import os 
import numpy as np 
import cv2 
import time
import threading
import subprocess 
import platform 
import onnxruntime 

try:
    import pigpio
except ImportError:
    pigpio = None
    print("[Dian_Duo] æœªæ‰¾åˆ° pigpio åº“ï¼ŒWindows ç¯å¢ƒå°†è·³è¿‡ç¡¬ä»¶ç›¸å…³æ“ä½œ")
#############################################################################################
if_sound = False
if_baffle_move  = False

#############################################################################################
# Baffle å…¨å±€é…ç½®å‚æ•°ï¼ˆæ–°å¢æ£€æµ‹é—´éš”é…ç½®ï¼‰
BLUE_LOWER = np.array([100, 150, 50])    # è“è‰² HSV ä¸‹é™
BLUE_UPPER = np.array([140, 255, 255])   # è“è‰² HSV ä¸Šé™
BLUE_AREA_THRESHOLD = 5000               # è“è‰²åŒºåŸŸæœ€å°é¢ç§¯é˜ˆå€¼
CHECK_INTERVAL = 5                       # çŠ¶æ€æ‰“å°é—´éš”ï¼ˆæ£€æµ‹å‘¨æœŸæ•°ï¼‰
DETECTION_INTERVAL = 0.25               # æ£€æµ‹é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰â†’ æ§åˆ¶æ£€æµ‹é€Ÿåº¦ï¼Œè¶Šå¤§è¶Šæ…¢
CONFIRM_FRAMES = 3                       # ç§»é™¤ç¡®è®¤å¸§æ•°ï¼ˆé¿å…è¯¯åˆ¤ï¼‰

#############################################################################################
# PID å‚æ•°
kp = 0.25
ki = 0.00
kd = 0.125

speed_val = 13000   # ç”µæœºæœ€å¤§å€¼
#############################################################################################
class Broadcast:
    def __init__(self):

        ####åˆå§‹åŒ–pygame 
        ####å…¶ä¸­æœ‰å…¨å±€å˜é‡æ§åˆ¶ if_soundæ˜¯å¦æ’­æ”¾ 
        ####ç±»æˆå‘˜å˜é‡ audio_initializedæ§åˆ¶æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ 
        #### å¦‚æœinitializedæˆåŠŸï¼Œåˆ™å¯ä»¥æ’­æ”¾éŸ³é¢‘ 
        ####æ•´ä½“è°ƒç”¨æµç¨‹:

        ###sound = Broadcast() 
        ###sound._play_sound(sound,speak )  å³å¯æ’­æ”¾éŸ³é¢‘ 

        ###æµ‹è¯•
        ###sound = Broadcast() 
        ###sound.test() æµ‹è¯•å‡½æ•°
        try:
            pygame.init()
            pygame.mixer.init()
            self.audio_initialized = True
            print("[Broadcast] pygame.mixer åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            ###å¦‚æœåˆå§‹åŒ–å¤±è´¥
            print(f"[Broadcast] pygame.mixer åˆå§‹åŒ–å¤±è´¥: {e}")
            self.audio_initialized = False

    def _play_sound(self, place, name):


        if not self.audio_initialized:
            print("[Broadcast] éŸ³é¢‘æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ’­æ”¾")
            return False 
        sound_path = f"files/{place}/{name}.mp3"

        print(f"[Broadcast] å°è¯•æ’­æ”¾: {sound_path}")
        if not os.path.exists(sound_path):
            print(f"[Broadcast] é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {sound_path}")
            return False 
        try:
            pygame.mixer.music.load(sound_path)
            pygame.mixer.music.play()
            print(f"[Broadcast] å¼€å§‹æ’­æ”¾ {name}")
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(20)
            print(f"[Broadcast] æ’­æ”¾å®Œæˆ {name}")  ###ç›´è‡³æ’­æ”¾å®Œæ¯•
            if_sound = True 
            return True 

        except Exception as e:
            print(f"[Broadcast] æ’­æ”¾å£°éŸ³å¤±è´¥: {e}")
            return False 
    def test(self): 
        ret= sound._play_sound("sound","speak") 
        print(ret)  

class Baffle:
    def __init__(self, cap_id=0):
        self.detection_complete = False  # æ•´ä¸ªæ£€æµ‹æµç¨‹æ˜¯å¦å®Œæˆ
        self.baffle_detected = False     # æ˜¯å¦å·²ç¡®è®¤æ£€æµ‹åˆ°æŒ¡æ¿
        self.cap = cv2.VideoCapture(cap_id)
        
        # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æ‰“å¼€æˆåŠŸ
        if not self.cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ cap{cap_id} (ID={cap_id})")
        
        # æ‘„åƒå¤´å‚æ•°é…ç½®ï¼ˆé™ä½èµ„æºå ç”¨ï¼‰
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 160)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 120)
        self.cap.set(cv2.CAP_PROP_FPS, 10)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        self.frame_count = 0
        self.detect_count = 0  # æ£€æµ‹å‘¨æœŸè®¡æ•°å™¨
        print(f"[find_baffle] æ‘„åƒå¤´ cap{cap_id} åˆå§‹åŒ–æˆåŠŸï¼ˆæ£€æµ‹é—´éš”ï¼š{DETECTION_INTERVAL}ç§’ï¼‰")

    def process_blue_area(self, frame):
        # å›ºå®š HSV é˜ˆå€¼ç­›é€‰è“è‰²åŒºåŸŸ
        lower = BLUE_LOWER
        upper = BLUE_UPPER

        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, lower, upper)

        # å½¢æ€å­¦æ“ä½œå»é™¤å™ªå£°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        return mask

    def find_blue_card(self, frame):
        mask = self.process_blue_area(frame)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

        if not contours:
            return False  # æ— æœ‰æ•ˆè“è‰²è½®å»“
        # å–æœ€å¤§è½®å»“é¢ç§¯åˆ¤æ–­
        max_area = cv2.contourArea(sorted(contours, key=cv2.contourArea, reverse=True)[0])
        # é™ä½æ‰“å°é¢‘ç‡
        if self.detect_count % CHECK_INTERVAL == 0:
            print(f"[find_baffle] æœ€å¤§è“è‰²åŒºåŸŸé¢ç§¯: {max_area:.1f} (é˜ˆå€¼: {BLUE_AREA_THRESHOLD})")
        return max_area > BLUE_AREA_THRESHOLD

    def detection_stream(self):
        print("[find_baffle] æŒ¡æ¿æ£€æµ‹çº¿ç¨‹å·²å¯åŠ¨...")
        print(f"[find_baffle] æ£€æµ‹é€Ÿåº¦ï¼šæ¯{DETECTION_INTERVAL}ç§’æ£€æµ‹ä¸€æ¬¡ï¼ˆæŒ‰ 'q' é”®é€€å‡ºï¼‰")
        print("[find_baffle] ç¬¬ä¸€æ­¥ï¼šç­‰å¾…æ£€æµ‹è“è‰²æŒ¡æ¿...")

        while not self.detection_complete:
            ret, frame = self.cap.read()
            if not ret:
                print("[find_baffle] æ•è·å¸§å¤±è´¥ï¼Œé‡è¯•...")
                time.sleep(DETECTION_INTERVAL)
                continue

            # æ£€æµ‹è®¡æ•°+1ï¼Œæ‰§è¡Œè“è‰²åŒºåŸŸæ£€æµ‹
            self.detect_count += 1
            has_blue = self.find_blue_card(frame)

            ###################################
            # é˜¶æ®µ1ï¼šç­‰å¾…æ£€æµ‹åˆ°è“è‰²æŒ¡æ¿ï¼ˆç¡®è®¤æŒ¡æ¿å­˜åœ¨ï¼‰
            ###################################
            if not self.baffle_detected:
                if has_blue:
                    print("\n[find_baffle] âœ… å·²æ£€æµ‹åˆ°è“è‰²æŒ¡æ¿ï¼")
                    print("[find_baffle] ç¬¬äºŒæ­¥ï¼šæŒç»­ç›‘æµ‹ï¼Œç­‰å¾…æŒ¡æ¿ç§»é™¤...")
                    self.baffle_detected = True  # è¿›å…¥é˜¶æ®µ2
                    self.frame_count = 0  # é‡ç½®ç§»é™¤ç¡®è®¤è®¡æ•°å™¨
                    self.detect_count = 0
                else:
                    # æ¯CHECK_INTERVALæ¬¡æ‰“å°ç­‰å¾…æç¤º
                    if self.detect_count % CHECK_INTERVAL == 0:
                        print("[find_baffle] ğŸ” æœªæ£€æµ‹åˆ°æŒ¡æ¿ï¼Œè¯·æ”¾ç½®è“è‰²æŒ¡æ¿...")

            ###################################
            # é˜¶æ®µ2ï¼šå·²æ£€æµ‹åˆ°æŒ¡æ¿ï¼Œç­‰å¾…å…¶ç§»é™¤ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰
            ###################################
            else:
                if not has_blue:
                    # è¿ç»­CONFIRM_FRAMESæ¬¡æœªæ£€æµ‹åˆ° â†’ ç¡®è®¤æŒ¡æ¿ç§»é™¤
                    self.frame_count += 1
                    if self.frame_count >= CONFIRM_FRAMES:
                        print(f"\n[find_baffle] ğŸ‰ è¿ç»­{CONFIRM_FRAMES}æ¬¡æœªæ£€æµ‹åˆ°æŒ¡æ¿ï¼Œç¡®è®¤å·²ç§»é™¤ï¼")
                        print("[find_baffle] æ£€æµ‹æµç¨‹å®Œæˆï¼")
                        self.detection_complete = True
                        break
                    else:
                        print(f"[find_baffle] æ£€æµ‹åˆ°æŒ¡æ¿æ¶ˆå¤±ï¼ˆè¿ç»­ {self.frame_count}/{CONFIRM_FRAMES} æ¬¡ï¼‰ï¼Œç¡®è®¤ä¸­...")
                else:
                    # ä»æ£€æµ‹åˆ°æŒ¡æ¿ â†’ é‡ç½®ç¡®è®¤è®¡æ•°å™¨
                    self.frame_count = 0
                    if self.detect_count % CHECK_INTERVAL == 0:
                        print("[find_baffle] ğŸ” æŒ¡æ¿ä»å­˜åœ¨ï¼ŒæŒç»­ç­‰å¾…ç§»é™¤...")

            ###################################
            # æŒ‰é”®é€€å‡º+æ£€æµ‹å»¶è¿Ÿï¼ˆæ§åˆ¶é€Ÿåº¦ï¼‰
            ###################################
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("[find_baffle] æ”¶åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œç¨‹åºç»ˆæ­¢")
                self.detection_complete = True
                break
            
            # æ¯æ¬¡æ£€æµ‹åå»¶è¿Ÿï¼Œæ ¸å¿ƒå‡é€Ÿé€»è¾‘
            time.sleep(DETECTION_INTERVAL)

        print("[find_baffle] æ£€æµ‹å·²åœæ­¢")

    def stop(self):
        self.cap.release()
        cv2.destroyAllWindows()
        print("[find_baffle] æ‘„åƒå¤´å·²é‡Šæ”¾ï¼Œèµ„æºæ¸…ç†å®Œæˆ")

    def test(self): 
        self.detection_stream() 
        self.stop()


class Control:
    def __init__(self):
        # åˆ¤æ–­æ“ä½œç³»ç»Ÿï¼šWindows ä¸æ‰§è¡Œç¡¬ä»¶åˆå§‹åŒ–
        self.os_type = platform.system()
        self.pi = None  # pigpio å®ä¾‹ï¼ˆLinuxæœ‰æ•ˆï¼ŒWindowsä¸ºNoneï¼‰
        
        if self.os_type != "Windows":
            self.start_pigpiod()
            self.pi = pigpio.pi()
            if not self.pi.connected:
                raise Exception("æ— æ³•è¿æ¥åˆ° pigpiod")

            self.last_error = 0
            self.sum_error = 0
            self.last_dian = 11800  # ç”µæœºåˆå§‹é€Ÿåº¦

            self.set_gpio()
            print("[Dian_Duo] åˆå§‹åŒ–å®Œæˆï¼ˆLinuxç¯å¢ƒï¼‰")
        else:
            # Windows ç¯å¢ƒåˆå§‹åŒ–å ä½å‚æ•°ï¼Œé¿å…å±æ€§ä¸å­˜åœ¨æŠ¥é”™
            self.last_error = 0
            self.sum_error = 0
            self.last_dian = 11800
            print("[Dian_Duo] åˆå§‹åŒ–å®Œæˆï¼ˆWindowsç¯å¢ƒï¼Œè·³è¿‡ç¡¬ä»¶æ“ä½œï¼‰")

    # -------------------------
    # å¯åŠ¨ pigpio å®ˆæŠ¤è¿›ç¨‹ï¼ˆä»…Linuxæ‰§è¡Œï¼‰
    # -------------------------
    def start_pigpiod(self):
        if self.os_type == "Windows":
            print("[Dian_Duo] Windowsç¯å¢ƒï¼Œä¸å¯åŠ¨ pigpiod")
            return
        
        try:
            result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
            if 'pigpiod' not in result.stdout:
                print("[Dian_Duo] pigpiod æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
                subprocess.Popen(['sudo', 'pigpiod'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(1)
                print("[Dian_Duo] pigpiod å·²å¯åŠ¨")
            else:
                print("[Dian_Duo] pigpiod å·²è¿è¡Œ")
        except Exception as e:
            print(f"[Dian_Duo] å¯åŠ¨ pigpiod å¤±è´¥: {e}")

    # -------------------------
    # GPIO åˆå§‹åŒ–ï¼ˆä»…Linuxæ‰§è¡Œï¼‰
    # -------------------------
    def set_gpio(self):
        if self.os_type == "Windows":
            print("[Dian_Duo] Windowsç¯å¢ƒï¼Œä¸åˆå§‹åŒ– GPIO")
            return

        # -------------- ç”µæœº PWM (13å·è„š) --------------
        self.pi.set_mode(13, pigpio.OUTPUT)
        self.pi.set_PWM_frequency(13, 200)     # 200Hz
        self.pi.set_PWM_range(13, 40000)       # 0~40000 çš„å¯è°ƒèŒƒå›´

        # -------------- èˆµæœº PWM (12å·è„š) --------------
        self.pi.set_mode(12, pigpio.OUTPUT)
        self.pi.set_PWM_frequency(12, 50)       # èˆµæœºå›ºå®š 50Hz
        # èˆµæœºç”¨ set_servo_pulsewidthï¼Œä¸éœ€è¦ set_PWM_range

        print("[Dian_Duo] GPIO åˆå§‹åŒ–å®Œæ¯•")

    # -------------------------
    # ç”µæœºå¹³æ»‘åŠ é€Ÿï¼ˆä»…Linuxæ‰§è¡Œï¼‰
    # -------------------------
    def set_dian(self, value):
        if self.os_type == "Windows":
            print(f"[Dian_Duo] Windowsç¯å¢ƒï¼Œè·³è¿‡ç”µæœºæ§åˆ¶ï¼ˆç›®æ ‡é€Ÿåº¦ï¼š{value}ï¼‰")
            return
        
        value = max(0, min(value, speed_val))

        if value > self.last_dian:
            start = max(10800, self.last_dian)
            for i in range(start, value + 1, 50):
                self.pi.set_PWM_dutycycle(13, i)
                time.sleep(0.02)
        else:
            self.pi.set_PWM_dutycycle(13, value)

        self.last_dian = value

    # -------------------------
    # PIDæ§åˆ¶ï¼ˆWindowsç¯å¢ƒä»…è®¡ç®—ä¸æ‰§è¡Œç¡¬ä»¶æ“ä½œï¼‰
    # -------------------------
    def pid(self, error):
        angle = kp * error + kd * (error - self.last_error)
        self.last_error = error
        print(f"[Dian_Duo] PIDè®¡ç®—å®Œæˆï¼Œè¾“å‡ºè§’åº¦ï¼š{angle:.2f}Â°")
        return angle

    # -------------------------
    # èˆµæœºåŠŸèƒ½ï¼š-90Â° åˆ° +90Â°ï¼ˆä»…Linuxæ‰§è¡Œï¼‰
    # ä½¿ç”¨è„‰å®½æ§åˆ¶ï¼ˆ500~2500 å¾®ç§’ï¼‰
    # -------------------------
    def set_duo(self, angle):
        if self.os_type == "Windows":
            print(f"[Dian_Duo] Windowsç¯å¢ƒï¼Œè·³è¿‡èˆµæœºæ§åˆ¶ï¼ˆç›®æ ‡è§’åº¦ï¼š{angle}Â°ï¼‰")
            return
        
        # é™åˆ¶è§’åº¦èŒƒå›´ï¼ˆ0Â°~180Â° å¯¹åº”ç‰©ç† -90Â°~+90Â°ï¼‰
        angle = max(0, min(180, angle))

        # 0Â° â†’ 500us ï¼Œ180Â° â†’ 2500us
        pulsewidth = 500 + (angle / 180.0) * 2000  

        print(f"[Dian_Duo] èˆµæœºè§’åº¦: {angle}Â°, è„‰å®½: {pulsewidth:.0f}us")
        self.pi.set_servo_pulsewidth(12, pulsewidth)

    # -------------------------
    # æ¸…ç†èµ„æºï¼ˆä»…Linuxæ‰§è¡Œï¼‰
    # -------------------------
    def cleanup(self):
        if self.os_type == "Windows":
            print("[Dian_Duo] Windowsç¯å¢ƒï¼Œè·³è¿‡èµ„æºé‡Šæ”¾")
            return
        
        if self.pi:
            self.pi.set_servo_pulsewidth(12, 0)
            self.pi.set_PWM_dutycycle(13, 0)
            self.pi.stop()
            print("[Dian_Duo] GPIO èµ„æºå·²é‡Šæ”¾")


class Yolo:
    def __init__(self, onnx_model_path, class_names_path, conf_thres=0.5, iou_thres=0.4):
        """
        åˆå§‹åŒ– YOLO ONNX æ£€æµ‹å™¨
        :param onnx_model_path: ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„
        :param class_names_path: ç±»åˆ«åç§°æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼‰
        :param conf_thres: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœï¼‰
        :param iou_thres: NMS çš„ IOU é˜ˆå€¼ï¼ˆå»é™¤é‡å¤æ£€æµ‹æ¡†ï¼‰
        """
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres
        self.class_names = self._load_class_names(class_names_path)
        self.input_shape = (480, 320)  # YOLO æ¨¡å‹é»˜è®¤è¾“å…¥å°ºå¯¸ï¼ˆæ ¹æ®æ¨¡å‹å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        
        # åˆå§‹åŒ– ONNX Runtime æ¨ç†ä¼šè¯
        self.session = self._init_onnx_session(onnx_model_path)
        # è·å–æ¨¡å‹è¾“å…¥åç§°
        self.input_name = self.session.get_inputs()[0].name

    def _init_onnx_session(self, model_path):
        """åˆå§‹åŒ– ONNX Runtime ä¼šè¯"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ONNX æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
        
        try:
            # é…ç½®æ¨ç†å‚æ•°ï¼ˆCPU æ¨ç†ï¼Œæ”¯æŒ GPU æ‰©å±•ï¼‰
            providers = ['CPUExecutionProvider']
            # è‹¥ç³»ç»Ÿæ”¯æŒ GPUï¼Œå¯æ·»åŠ  CUDA  providerï¼ˆéœ€å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ onnxruntime-gpuï¼‰
            # if onnxruntime.get_device() == 'GPU':
            #     providers.insert(0, 'CUDAExecutionProvider')
            
            session = onnxruntime.InferenceSession(
                model_path,
                providers=providers,
                provider_options=[{'device_id': 0}] if 'CUDAExecutionProvider' in providers else None
            )
            print(f"[Yolo] ONNX æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_path}")
            print(f"[Yolo] æ¨ç†è®¾å¤‡ï¼š{providers[0]}")
            return session
        except Exception as e:
            raise RuntimeError(f"ONNX æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

    def _load_class_names(self, class_path):
        """åŠ è½½ç±»åˆ«åç§°åˆ—è¡¨"""
        if not os.path.exists(class_path):
            raise FileNotFoundError(f"ç±»åˆ«æ–‡ä»¶ä¸å­˜åœ¨ï¼š{class_path}")
        
        with open(class_path, 'r', encoding='utf-8') as f:
            class_names = [line.strip() for line in f.readlines() if line.strip()]
        print(f"[Yolo] åŠ è½½ç±»åˆ«æ•°ï¼š{len(class_names)}")
        return class_names

    def _preprocess(self, frame):
        """å›¾åƒé¢„å¤„ç†ï¼šç¼©æ”¾ã€å½’ä¸€åŒ–ã€ç»´åº¦è½¬æ¢"""
        # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆç”¨äºåç»­è¿˜åŸæ£€æµ‹æ¡†ï¼‰
        self.orig_h, self.orig_w = frame.shape[:2]
        
        # ç¼©æ”¾å›¾åƒåˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼ˆä¿æŒé•¿å®½æ¯”ï¼Œå¡«å……é»‘è¾¹ï¼‰
        img = cv2.resize(frame, self.input_shape, interpolation=cv2.INTER_LINEAR)
        # å½’ä¸€åŒ–ï¼šåƒç´ å€¼ä» [0,255] è½¬ä¸º [0,1]
        img = img / 255.0
        # ç»´åº¦è½¬æ¢ï¼š(H,W,C) â†’ (C,H,W) â†’ (1,C,H,W)ï¼ˆæ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰
        img = np.transpose(img, (2, 0, 1)).astype(np.float32)
        img = np.expand_dims(img, axis=0)
        return img

    def _postprocess(self, outputs):
        """åå¤„ç†ï¼šè§£ææ¨¡å‹è¾“å‡ºï¼Œè¿‡æ»¤ä½ç½®ä¿¡åº¦ï¼ŒNMS å»é‡"""
        # YOLO æ¨¡å‹è¾“å‡ºæ ¼å¼ï¼š(1, num_boxes, num_params) â†’ num_params åŒ…å« (x1,y1,x2,y2,conf,class_id,...)
        outputs = outputs[0]  # å»é™¤ batch ç»´åº¦
        boxes = []
        confidences = []
        class_ids = []

        # è§£ææ¯ä¸ªæ£€æµ‹æ¡†
        for out in outputs:
            if len(out) < 5:
                continue  # æ— æ•ˆæ£€æµ‹æ¡†è·³è¿‡
            x1, y1, x2, y2, conf = out[:5]
            class_scores = out[5:]
            class_id = np.argmax(class_scores)
            class_conf = class_scores[class_id]
            total_conf = conf * class_conf  # ç½®ä¿¡åº¦ = æ¡†ç½®ä¿¡åº¦ Ã— ç±»åˆ«ç½®ä¿¡åº¦

            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹æ¡†
            if total_conf >= self.conf_thres:
                # è¿˜åŸæ£€æµ‹æ¡†åˆ°åŸå§‹å›¾åƒå°ºå¯¸
                x1 = int(x1 * self.orig_w / self.input_shape[1])
                y1 = int(y1 * self.orig_h / self.input_shape[0])
                x2 = int(x2 * self.orig_w / self.input_shape[1])
                y2 = int(y2 * self.orig_h / self.input_shape[0])
                boxes.append([x1, y1, x2, y2])
                confidences.append(float(total_conf))
                class_ids.append(class_id)

        # NMS å»é™¤é‡å¤æ£€æµ‹æ¡†
        indices = cv2.dnn.NMSBoxes(
            boxes, confidences, self.conf_thres, self.iou_thres
        )

        # æ•´ç†æœ€ç»ˆæ£€æµ‹ç»“æœ
        results = []
        if len(indices) > 0:
            for i in indices.flatten():
                results.append({
                    "box": boxes[i],  # [x1,y1,x2,y2]
                    "confidence": confidences[i],  # ç½®ä¿¡åº¦
                    "class_id": class_ids[i],  # ç±»åˆ«ID
                    "class_name": self.class_names[class_ids[i]]  # ç±»åˆ«åç§°
                })
        return results

    def detect(self, frame):
        """æ ¸å¿ƒæ£€æµ‹å‡½æ•°ï¼šè¾“å…¥å›¾åƒå¸§ï¼Œè¿”å›æ£€æµ‹ç»“æœ"""
        if frame is None:
            print("[Yolo] è¾“å…¥å›¾åƒä¸ºç©ºï¼Œè·³è¿‡æ£€æµ‹")
            return []
        
        # 1. å›¾åƒé¢„å¤„ç†
        input_img = self._preprocess(frame)
        
        # 2. ONNX æ¨¡å‹æ¨ç†
        try:
            outputs = self.session.run(None, {self.input_name: input_img})
        except Exception as e:
            print(f"[Yolo] æ¨ç†å¤±è´¥ï¼š{e}")
            return []
        
        # 3. ç»“æœåå¤„ç†
        results = self._postprocess(outputs)
        print(f"[Yolo] æ£€æµ‹åˆ° {len(results)} ä¸ªç›®æ ‡")
        return results

    def draw_detections(self, frame, results):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾ï¼ˆå¯é€‰å¯è§†åŒ–ï¼‰"""
        for res in results:
            x1, y1, x2, y2 = res["box"]
            class_name = res["class_name"]
            confidence = res["confidence"]
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆè“è‰²ï¼Œçº¿å®½2ï¼‰
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯ï¼ˆé»‘è‰²åŠé€æ˜ï¼‰
            label = f"{class_name} {confidence:.2f}"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            label_y1 = max(y1 - label_size[1] - 5, 0)
            cv2.rectangle(
                frame, (x1, label_y1), (x1 + label_size[0], y1 - 2),
                (0, 0, 0), -1
            )
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—ï¼ˆç™½è‰²ï¼‰
            cv2.putText(
                frame, label, (x1, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1
            )
        return frame

    def test(self, test_img_path, save_output=True):
        """æµ‹è¯•å‡½æ•°ï¼šåŠ è½½å•å¼ å›¾åƒè¿›è¡Œæ£€æµ‹ï¼Œå¯é€‰ä¿å­˜ç»“æœ"""
        frame = cv2.imread(test_img_path)
        if frame is None:
            print(f"[Yolo] æ— æ³•è¯»å–æµ‹è¯•å›¾åƒï¼š{test_img_path}")
            return
        
        # æ‰§è¡Œæ£€æµ‹
        results = self.detect(frame)
        # ç»˜åˆ¶ç»“æœ
        frame_with_detections = self.draw_detections(frame, results)
        
        # æ˜¾ç¤ºç»“æœï¼ˆLinuxç¯å¢ƒå¯ç›´æ¥æ˜¾ç¤ºï¼ŒWindowséœ€è°ƒæ•´çª—å£é…ç½®ï¼‰
        if platform.system() != "Windows":
            cv2.imshow("[Yolo] æ£€æµ‹ç»“æœ", frame_with_detections)
            print("[Yolo] æŒ‰ 'q' é”®å…³é—­çª—å£")
            while cv2.waitKey(1) & 0xFF != ord('q'):
                continue
            cv2.destroyAllWindows()
        
        # ä¿å­˜ç»“æœ
        if save_output:
            output_path = "yolo_detection_result.jpg"
            cv2.imwrite(output_path, frame_with_detections)
            print(f"[Yolo] æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")

def Line_stream():
    ...

if __name__ == "__main__": 
    sound = Broadcast()
    baffle = Baffle()
    baffle.test()


